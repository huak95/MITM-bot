{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/mitm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-29 08:40:00,982 - Loading faiss.\n",
      "2024-06-29 08:40:00,991 - Successfully loaded faiss.\n"
     ]
    }
   ],
   "source": [
    "from rapper import custom_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Union\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from langchain_core.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.llms import LLM\n",
    "from langchain_core.pydantic_v1 import Field, SecretStr\n",
    "\n",
    "class SnovaLLM(LLM):\n",
    "    \"\"\"Custom LLM for Snova AI API integration with LangChain.\n",
    "\n",
    "    This LLM uses the Snova AI API to generate responses based on given prompts.\n",
    "\n",
    "    Attributes:\n",
    "        model (str): The model to use for generation. Defaults to \"llama3-8b-typhoon\".\n",
    "        temperature (float): The sampling temperature. Defaults to 0.7.\n",
    "        top_k (int): The number of top tokens to consider. Defaults to 50.\n",
    "        top_p (float): The cumulative probability threshold for top-p sampling. Defaults to 0.95.\n",
    "        base_url (str): The base URL for the Snova AI API. Defaults to \"https://kjddazcq2e2wzvzv.snova.ai/api/v1/chat/completion\".\n",
    "        api_key (SecretStr): The API key for authentication.\n",
    "\n",
    "    Example:\n",
    "        .. code-block:: python\n",
    "\n",
    "            llm = SnovaLLM(api_key=\"your-api-key-here\")\n",
    "            result = llm.invoke(\"Tell me a joke about programming.\")\n",
    "    \"\"\"\n",
    "\n",
    "    model: str = Field(default=\"llama3-8b-typhoon\")\n",
    "    temperature: float = Field(default=0.7)\n",
    "    top_k: int = Field(default=50)\n",
    "    top_p: float = Field(default=0.95)\n",
    "    max_tokens_to_generate: int = Field(default=4096)\n",
    "    base_url: str = Field(default=\"https://kjddazcq2e2wzvzv.snova.ai/api/v1/chat/completion\")\n",
    "    api_key: SecretStr = Field(...)\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        \"\"\"Generate a response using the Snova AI API.\n",
    "\n",
    "        Args:\n",
    "            prompt (str): The prompt to generate from.\n",
    "            stop (Optional[List[str]]): Stop sequences for generation.\n",
    "            run_manager (Optional[CallbackManagerForLLMRun]): Callback manager for the run.\n",
    "            **kwargs: Additional keyword arguments.\n",
    "\n",
    "        Returns:\n",
    "            str: The generated response.\n",
    "        \"\"\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Basic {self.api_key.get_secret_value()}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        data = {\n",
    "            \"inputs\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            \"max_tokens_to_generate\": self.max_tokens_to_generate,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"top_k\": self.top_k,\n",
    "            \"top_p\": self.top_p,\n",
    "            \"model\": self.model,\n",
    "            \"stop\": stop or [\"<|eot_id|>\", \"<|end_of_text|>\"],\n",
    "        }\n",
    "\n",
    "        response = requests.post(self.base_url, headers=headers, data=json.dumps(data))\n",
    "        response.raise_for_status()\n",
    "\n",
    "        lines_result = response.text.strip().split(\"\\n\")\n",
    "        text_result = lines_result[-1].replace(\"data: \", '')\n",
    "        out = json.loads(text_result)\n",
    "\n",
    "        return out['completion']\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return the type of LLM.\"\"\"\n",
    "        return \"snova_ai\"\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {\n",
    "            \"model_name\": self.model,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"top_k\": self.top_k,\n",
    "            \"top_p\": self.top_p,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = SnovaLLM(api_key=\"\")\n",
    "result = llm.invoke(\"Tell me a joke about programming.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"You are a helpful assistant named Typhoon. You always answer in Thai.\"), (\"human\", \"{input}\")]\n",
    ")\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant named Typhoon. You always answer in Thai.'), HumanMessage(content='Hwllo')])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke(\"Hwllo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ฉันชื่อไต้ฝุ่น (Typhoon)'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"คุณชื่ออะไร\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Agentic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def get_retriver(url):\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "    documents = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, chunk_overlap=200\n",
    "    ).split_documents(docs)\n",
    "    vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "    retriever = vector.as_retriever()\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 09:13:55,732 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-06-29 09:13:56,970 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_langsmith_tool = create_retriever_tool(\n",
    "    get_retriver(\"https://docs.smith.langchain.com/overview\"),\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")\n",
    "\n",
    "retriever_scb10x_tool = create_retriever_tool(\n",
    "    get_retriver(\"https://www.blognone.com/node/131737\"),\n",
    "    \"scb10x_mission\",\n",
    "    \"Search for information about SCB10x. For any questions about SCB10x, you must use this tool!\",\n",
    ")\n",
    "\n",
    "tools = [retriever_langsmith_tool, retriever_scb10x_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='langsmith_search', description='Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x3088b1000>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x309a2f8b0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x3088b11b0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x309a2f8b0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n')),\n",
       " Tool(name='scb10x_mission', description='Search for information about SCB10x. For any questions about SCB10x, you must use this tool!', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x3088b1000>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x309ae6d70>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x3088b11b0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x309ae6d70>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 09:23:18,625 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ก้าวต่อไปของ SCB 10X กับการปั้นยูนิคอร์นไทย และเป้าหมายเบอร์ 1 CVC\\n\\n\\n\\nBy: workplace  on 6 December 2022 - 10:30\\nTags:Topics:\\xa0SCB10XSCBBlognone Workplace\\n\\n\\n\\n\\nกลุ่มธนาคารไทยพาณิชย์เป็นหนึ่งในธนาคารแรกๆ ในไทยที่มีการปรับตัวเพื่อเปลี่ยนผ่านสู่สิ่งใหม่ๆ สำหรับด้านอุตสาหกรรมการเงินและการธนาคาร ตั้งแต่นวัตกรรม เทคโนโลยี ไปจนถึงวัฒนธรรมองค์กร โดยการตั้ง SCB 10X ขึ้นมาเพื่อตอบโจทย์ดังกล่าว\\nซึ่งทาง SCB 10X เองก็ผ่านการเปลี่ยนแปลงทั้งในเชิงโครงสร้างองค์กรและเป้าหมาย จากจุดเริ่มต้นที่เป็นเพียงหน่วยงานย่อยภายใน SCB  เป้าหมายเพื่อสร้างนวัตกรรมใหม่ๆ ก่อนจะกลายมาเป็นบริษัทแยกของตัวเองในปัจจุบัน โดยมีเป้าหมายเพื่อลงทุนและสร้างธุรกิจสตาร์ทอัพใหม่ ๆ ภายใต้แนวคิด Moonshot Mission หรือการคิดและทำ มองเห็นความต้องการของตลาดก่อนคนอื่น\\n\\nวัฒนธรรมการทำงาน\\nความโดดเด่นของ SCB 10X คือการเป็นลูกผสมระหว่างสตาร์ทอัพและบริษัทใหญ่ ทำให้มีบรรยากาศการทำงานเหมือนสตาร์อัพ แต่มีความมั่นคง ในแง่ของความพร้อมเชิงบุคคลากรที่เชี่ยวชาญด้านเทคโนโลยี ด้านการลงทุน พัฒนานวัตกรรม และเงินลงทุน มีรูปแบบการทำงานที่คล่องตัว สนุกสนาน สร้างสรรค์ และมีสวัสดิการการดูแลพนักงานเหมือนกับองค์กรขนาดใหญ่\\nที่สำคัญคือ SCB 10X ให้ความสำคัญกับ “คน” เป็นอันดับแรก เพราะเชื่อว่าคนคือฟันเฟืองสำคัญที่สุดในการทำภารกิจให้สำเร็จ บริษัทจึงให้ความสำคัญกับการของวางรากฐานที่คน และมองว่าคนของ SCB 10X จะต้องมี Mindset  มี Attitude  ที่ก้าวไปข้างหน้า  กล้าทำในสิ่งใหม่ๆ กล้าล้มเหลว  อยากร่วมสร้างธุรกิจมีความฝันและพร้อมก้าวเดินไปด้วยกัน\\n\\nSCB 10X ในปัจจุบัน\\nปัจจุบัน SCB 10X มี SCBX ถือหุ้น 100% ซึ่งคุณ ไพลิน วิชากูล ตำแหน่ง Chief Operating Officer, Head of Strategic Planning, and Partner – Venture Capital บอกว่าฐานะของ SCB 10X เป็นเหมือน Venture Capital และ Innovation Arm ให้กับ กลุ่ม SCBX\\nคุณไพลิน วิชากูล ตำแหน่ง Chief Operating Officer, Head of Strategic Planning, and Partner – Venture Capital\\nภารกิจใหญ่ของ SCB 10X คือสร้างขีดความสามารถใหม่ทางด้านเทคโนโลยี ผ่านการสร้างและพัฒนานวัตกรรมเพื่อ Spin-Off ไปเป็นสตาร์ทอัพ (Venture Builder) และการลงทุนในสตาร์ทอัพชั้นนำด้านเทคโนโลยี (Venture Capital) ที่สามารถสร้างการเติบโตแบบก้าวกระโดด ซึ่งเป็นความพยายามคิดใหม่ทำใหม่ และกล้ารับความเสี่ยง เพื่อการเติบโตอย่างก้าวกระโดดและอยู่รอดอย่างยั่งยืน และภารกิจทั้งหมดทั้งมวลนี้ถูกเรียกรวมๆ ว่าเป็น Moonshot Mission\\n\\nสำหรับคนของ SCB 10X จะเรียกตัวเองว่า “10Xers” มี core value อยู่ด้วยกัน 5 ข้อ ที่เรียกกันว่า B-O-O-S-T มาจาก Boldness, Ownership, Open, Speed, Trust for Impact ซึ่งบริษัทเชื่อว่า 5 ข้อนี้เป็นสิ่งที่ช่วยกำหนดและตีกรอบการทำงานของเราให้ไปถึงภารกิจที่ตั้งใจไว้ได้\\nออฟฟิศของ SCB 10X ก็เดินทางง่าย อยู่ที่อาคาร FYI Center สถานี MRT ศูนย์ประชุมแห่งชาติสิริกิติ์ หากใครเห็นภาพรวมแล้วสนใจอยากจะเป็นส่วนหนึ่งของที่นี่ ดูตำแหน่งที่เปิดรับได้ที่ Blognone Jobs\\n \\n\\n\\n\\n\\n\\n      FB Share\\n  \\n\\n\\n \\nGet latest news from Blognone\\n\\nFollow @twitterapi\\n\\n\\n \\n\\n\\n\\nHiring! บริษัทที่น่าสนใจ\\n\\n\\n\\n\\n\\n\\n\\nNational ITMX Co., Ltd.\\nA company who provides national payment infrastructure of Thailand, looking for talents.\\n\\n \\n\\n\\n\\n\\nJitta\\nAs a Jittstor, we help investors create better returns through simple investment methods\\n\\n \\n\\n\\n\\n\\nSkillLane Technology Public Company Limited\\nSkillLane is Thailand’s leading digital learning solution that provides instant access to knowledge.\\n\\n \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nsign in\\n\\n\\nลงทะเบียน\\nลืมรหัสผ่าน'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://python.langchain.com/v0.1/docs/use_cases/tool_use/prompting/\n",
    "from operator import itemgetter\n",
    "from langchain.tools.render import render_text_description\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "def tool_chain(model_output):\n",
    "    tool_map = {tool.name: tool for tool in tools}\n",
    "    chosen_tool = tool_map[model_output[\"name\"]]\n",
    "    return itemgetter(\"arguments\") | chosen_tool\n",
    "\n",
    "rendered_tools = render_text_description(tools)\n",
    "system_prompt = f\"\"\"You are an assistant that has access to the following set of tools. Here are the names and descriptions for each tool:\n",
    "\n",
    "{rendered_tools}\n",
    "\n",
    "Given the user input, return the name and input of the tool to use. Return your response as a JSON blob with 'name' and 'arguments' keys.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_prompt), (\"user\", \"{input}\")]\n",
    ")\n",
    "\n",
    "chain = prompt | llm | JsonOutputParser() | tool_chain\n",
    "chain.invoke({\"input\": \"What is SCB10x answer in Thai\", 'page_content': ''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
